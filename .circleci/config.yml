version: 2.1

parameters:
  release_kedro:
    type: boolean
    default: false

orbs:
  win: circleci/windows@2.2.0

# No windows executor is listed here since windows builds use win/default and modify
# the Python version through the conda environment.
executors:
  docker:
    parameters:
      python_version:
        type: string
    docker:
      - image: 350138855857.dkr.ecr.eu-west-2.amazonaws.com/kedro-builder:<<parameters.python_version>>
    resource_class: medium+

commands:
  setup_conda:
    steps:
      - run:
          name: Run conda.sh
          command: echo ". /home/circleci/miniconda/etc/profile.d/conda.sh" >> $BASH_ENV
      - run:
          name: Activate conda environment
          command: echo "conda deactivate; conda activate kedro_builder" >> $BASH_ENV

  setup_requirements:
    steps:
      - run:
          name: Install pip setuptools
          command: make install-pip-setuptools
      - run:
          # Virtualenv 20.0.20 broke pre-commit, capped for now
          name: Install venv for some pre-commit hooks
          command: conda install -y "virtualenv<20.0"
      - run:
          name: Install requirements and test requirements
          command: pip install --upgrade -r test_requirements.txt
      - run:
          # this is needed to fix java cacerts so
          # spark can automatically download packages from mvn
          # https://stackoverflow.com/a/50103533/1684058
          name: Fix cacerts
          command: |
            sudo rm /etc/ssl/certs/java/cacerts
            sudo update-ca-certificates -f
      - run:
          # Since recently Spark installation for some reason does not have enough permissions to execute
          # /home/circleci/miniconda/envs/kedro_builder/lib/python3.X/site-packages/pyspark/bin/spark-class.
          # So fixing it manually here.
          name: Fix Spark permissions
          command: sudo chmod -R u+x /home/circleci/miniconda/envs/kedro_builder/lib/
      - run:
          name: Print Python environment
          command: make print-python-env
      - run:
          name: Pip freeze
          command: pip freeze

  setup:
    steps:
      - checkout
      - setup_conda
      - setup_requirements

  # Windows specific commands
  win_setup_conda:
    parameters:
      python_version:
        type: string
    steps:
      - run:
          name: Initialize conda
          command: conda init powershell
      - run:
          name: Create 'kedro_builder' conda environment
          command: conda create -n kedro_builder python=<<parameters.python_version>> -y

  win_setup_env:
    steps:
      - run:
          # Required for Tensorflow tests
          name: Install Microsoft Visual C++ Redistributable
          command: |
            $ProgressPreference = "SilentlyContinue"
            Invoke-WebRequest https://aka.ms/vs/16/release/vc_redist.x64.exe -OutFile vc_redist.x64.exe
            .\vc_redist.x64.exe /S /v/qn
      - run:
          name: Install Java 8
          command: |
            $ProgressPreference = "SilentlyContinue"
            Invoke-WebRequest https://github.com/AdoptOpenJDK/openjdk8-upstream-binaries/releases/download/jdk8u252-b09/OpenJDK8U-jdk_x64_windows_8u252b09.zip -OutFile OpenJDK8U.zip
            Expand-Archive .\OpenJDK8U.zip -DestinationPath C:\OpenJDK8U
      - run:
          name: Create Inbound rules for Java
          command: |
            New-NetFirewallRule -DisplayName "Allow JDK UDP" -Profile "Public" -Protocol "UDP" -Direction Inbound -Program "C:\OpenJDK8U\openjdk-8u252-b09\bin\java.exe" -Action Allow
            New-NetFirewallRule -DisplayName "Allow JDK TCP" -Profile "Public" -Protocol "TCP" -Direction Inbound -Program "C:\OpenJDK8U\openjdk-8u252-b09\bin\java.exe" -Action Allow
      - run:
          name: Set Java environment variables
          command: |
            [Environment]::SetEnvironmentVariable("Path", [Environment]::GetEnvironmentVariable('Path', 'Machine') + ";C:\OpenJDK8U\openjdk-8u252-b09\bin", "Machine")
            setx /m JAVA_HOME "C:\OpenJDK8U\openjdk-8u252-b09"
      - run:
          name: Setup Hadoop binary
          command: |
            $ProgressPreference = "SilentlyContinue"
            Invoke-WebRequest https://github.com/steveloughran/winutils/raw/master/hadoop-2.6.3/bin/winutils.exe -OutFile winutils.exe
            New-Item -ItemType directory -Path C:\hadoop\bin
            mv .\winutils.exe C:\hadoop\bin
            setx /m HADOOP_HOME "C:\hadoop\"
      - run:
          name: Install 'make' command
          command: choco install make

  win_setup_requirements:
    steps:
      - run:
          name: Install GDAL
          command: conda activate kedro_builder; conda install -c conda-forge gdal -y
      - run:
          name: Install Fiona
          command: conda activate kedro_builder; conda install -c conda-forge fiona -y
      - run:
          name: Install all requirements
          command: conda activate kedro_builder; pip install -r test_requirements.txt -U
      - run:
          name: Print Python environment
          command: conda activate kedro_builder; make print-python-env
      - run:
          name: Pip freeze
          command: conda activate kedro_builder; pip freeze

  win_setup:
    parameters:
      python_version:
        type: string
    steps:
      - checkout
      - win_setup_conda:
          python_version: <<parameters.python_version>>
      - win_setup_env
      - restore_cache:
          key: kedro-deps-v1-win-{{ checksum "requirements.txt" }}-{{ checksum "test_requirements.txt" }}
      - win_setup_requirements

jobs:
  e2e_tests:
    parameters:
      python_version:
        type: string
    executor:
      name: docker
      python_version: <<parameters.python_version>>
    steps:
      - setup
      - run:
          name: Run e2e tests
          command: make e2e-tests

  win_e2e_tests:
    parameters:
      python_version:
        type: string
    executor: win/default
    steps:
      - checkout
      - win_setup_conda:
          python_version: <<parameters.python_version>>
      - run:
          name: Install 'make' command
          command: choco install make
      - run:
          name: Install dependencies
          command: conda activate kedro_builder; pip install -r features/windows_reqs.txt
      - run:
          name: Run e2e tests
          command: conda activate kedro_builder; make e2e-tests

  unit_tests:
    parameters:
      python_version:
        type: string
    executor:
      name: docker
      python_version: <<parameters.python_version>>
    steps:
      - setup
      - run:
          name: Run unit tests
          command: make test

  win_unit_tests:
    parameters:
      python_version:
        type: string
    executor: win/default
    steps:
      - win_setup:
          python_version: <<parameters.python_version>>
      - run:
          # geopandas and tensorflow conflicts when imported simultaneously.
          # The HDF5 header files used to compile this application do not match
          # the version used by the HDF5 library to which this application is linked.
          # Data corruption or segmentation faults may occur if the application continues.
          # This can happen when an application was compiled by one version of HDF5 but
          # linked with a different version of static or shared HDF5 library.
          # You should recompile the application or check your shared library related
          # settings such as 'LD_LIBRARY_PATH'.
          # You can, at your own risk, disable this warning by setting the environment
          # variable 'HDF5_DISABLE_VERSION_CHECK' to a value of '1'.
          # Setting it to 2 or higher will suppress the warning messages totally.
          name: Set HDF5_DISABLE_VERSION_CHECK environment variable
          command: setx /m HDF5_DISABLE_VERSION_CHECK 1
      - unless:
          condition:
            equal: ["3.6", <<parameters.python_version>>]
          steps:
            - run:
                name: Run unit tests without spark
                command: conda activate kedro_builder; make test-no-spark
      - when:
          condition:
            equal: ["3.6", <<parameters.python_version>>]
          steps:
            - run:
                name: Run unit tests without spark or tensorflow
                command: conda activate kedro_builder; pytest tests --no-cov --ignore tests/extras/datasets/spark --ignore tests/extras/datasets/tensorflow --numprocesses 4 --dist loadfile

  lint:
    parameters:
      python_version:
        type: string
    executor:
      name: docker
      python_version: <<parameters.python_version>>
    steps:
      - setup
      - run:
          name: Run linters
          command: make lint

  pip_compile:
    parameters:
      python_version:
        type: string
    executor:
      name: docker
      python_version: <<parameters.python_version>>
    steps:
      - setup
      - run:
          name: Pip-compile requirements file
          command: make pip-compile

  win_pip_compile:
    parameters:
      python_version:
        type: string
    executor: win/default
    steps:
      - win_setup:
          python_version: <<parameters.python_version>>
      - when:
          # Save cache only for Python 3.7. There is no need to save it for each Python.
          condition:
            equal: ["3.7", <<parameters.python_version>>]
          steps:
            - save_cache:
                key: kedro-deps-v1-win-{{ checksum "requirements.txt" }}-{{ checksum "test_requirements.txt" }}
                paths:
                  # Cache pip cache and conda packages directories
                  - c:\tools\miniconda3\pkgs
                  - c:\users\circleci\appdata\local\pip\cache
      - run:
          name: Pip-compile requirements file
          command: conda activate kedro_builder; make pip-compile

  build_docs:
    executor:
      name: docker
      python_version: "3.7"
    steps:
      - setup
      - run:
          name: Build docs
          command: make build-docs

  docs_linkcheck:
    executor:
      name: docker
      python_version: "3.7"
    steps:
      - setup
      - run:
          name: Check for broken links
          command: make linkcheck

  sync:
    docker:
      # https://circleci.com/docs/2.0/circleci-images/#circleci-base-image
      - image: cimg/base:2020.01
    steps:
      - checkout
      - add_ssh_keys
      - run:
          name: Set git email and name
          command: |
            git config --global user.email "kedro@quantumblack.com"
            git config --global user.name "QuantumBlack Labs"
      - run:
          name: Trigger Read The Docs build
          command: ./tools/circleci/rtd-build.sh ${RTD_TOKEN} latest
      - run:
          name: Maybe merge main into develop or raise a PR
          command: ./tools/circleci/github_scripts/merge.sh . "main" "develop" "${GITHUB_TAGGING_TOKEN}"
      - run:
          name: Maybe trigger the release workflow
          command: |
              KEDRO_VERSION=$(./tools/circleci/github_scripts/kedro_version.py ./kedro)

              if ./tools/circleci/check-no-version-pypi.sh "${KEDRO_VERSION}"
              then
                  echo "Starting the release of Kedro ${KEDRO_VERSION}!"
                  ./tools/circleci/circle-release.sh github/quantumblacklabs/kedro
              else
                  echo "Kedro version ${KEDRO_VERSION} already exists on PyPI, skipping..."
              fi

  merge_pr_to_develop:
    docker:
      # https://circleci.com/docs/2.0/circleci-images/#circleci-base-image
      - image: cimg/base:2020.01
    steps:
      - checkout
      - add_ssh_keys
      - run:
          name: Maybe merge an automatic PR into develop
          command: ./tools/circleci/github_scripts/attempt_merge_pr.sh "merge-main-to-develop" "develop" "${GITHUB_TAGGING_TOKEN}"

  build_docker_image:
    docker:
      - image: cimg/python:3.8
    environment:
      ECR_IMAGE_URL: 350138855857.dkr.ecr.eu-west-2.amazonaws.com/kedro-builder
      AWS_REGION: eu-west-2
    steps:
      - setup_remote_docker:
          docker_layer_caching: true
      - checkout
      - run:
          name: Setup AWS CLI
          command: pip install -U awscli
      - run:
          name: Login to AWS ECR
          command: |
            aws ecr get-login-password --region ${AWS_REGION} | \
            docker login --username AWS --password-stdin "${ECR_IMAGE_URL}"
      - run:
          name: Build docker images
          command: ./tools/circleci/docker_build_img/build.sh "." "${ECR_IMAGE_URL}"
          no_output_timeout: 20m
      - run:
          name: Logout from AWS ECR
          command: docker logout "${ECR_IMAGE_URL}"
          when: always  # logout even if the previous step has failed

  # This is effectively just a combination of the lint, unit_tests and e2e_tests jobs.
  # It's used to check that the nightly docker image is working ok and before publishing a release.
  build_kedro:
    parameters:
      python_version:
        type: string
    executor:
      name: docker
      python_version: <<parameters.python_version>>
    steps:
      - setup
      - run:
          name: Run linters
          command: make lint
      - run:
          name: Run unit tests
          command: make test
      - run:
          name: Run e2e tests
          command: make e2e-tests

  publish_kedro:
    executor:
      name: docker
      python_version: "3.7"
    steps:
      - setup
      - add_ssh_keys
      - run:
          name: Check Kedro version
          command: |
            KEDRO_VERSION=$(./tools/circleci/github_scripts/kedro_version.py ./kedro)

            if ./tools/circleci/check-no-version-pypi.sh "${KEDRO_VERSION}"
            then
                echo "export KEDRO_VERSION=\"${KEDRO_VERSION}\"" >> $BASH_ENV
            else
                echo "Error: Kedro version ${KEDRO_VERSION} already exists on PyPI"
                exit 1
            fi
      - run:
          name: Tag and publish release on Github
          command: ./tools/circleci/github_scripts/release.sh quantumblacklabs kedro ${GITHUB_TAGGING_TOKEN} ${KEDRO_VERSION}
      - run:
          name: Publish to PyPI
          command: |
            make package
            python -m pip install twine -U
            python -m twine upload --repository-url ${TWINE_REPOSITORY_URL} dist/*
      - run:
          name: Trigger Read The Docs build
          command: |
            ./tools/circleci/rtd-build.sh ${RTD_TOKEN} stable
            # give some time for GitHub release to propagate
            # otherwise RTD fails to build a new tag
            sleep 120
            ./tools/circleci/rtd-build.sh ${RTD_TOKEN} ${KEDRO_VERSION}

  # Trigger kedro-viz build to ensure tests in that project pass
  viz_build:
    docker:
      - image: spotify/alpine # for bash and curl
    steps:
      - run:
          name: Trigger kedro-viz build
          command: |
            curl --location --request POST \
              --url https://circleci.com/api/v2/project/github/quantumblacklabs/kedro-viz/pipeline \
              --header "Circle-Token: $CIRCLE_VIZ_BUILD_TOKEN" \
              --header 'content-type: application/json' \
              --data '{"branch":"main"}'

  all_circleci_checks_succeeded:
    docker:
      - image: circleci/python # any light-weight image
    steps:
      - run:
          name: Success!
          command: echo "All checks passed"

workflows:
  version: 2.1

  regular:
    unless: <<pipeline.parameters.release_kedro>>  # don't run if 'release_kedro' flag is set
    jobs:
      - e2e_tests:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - win_e2e_tests:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - unit_tests:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - win_unit_tests:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - lint:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - pip_compile:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - win_pip_compile:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - build_docs
      - docs_linkcheck
      - all_circleci_checks_succeeded:
          requires:
            - e2e_tests
            - win_e2e_tests
            - unit_tests
            - win_unit_tests
            - lint
            - pip_compile
            - win_pip_compile
            - build_docs
            - docs_linkcheck

  main_updated:
    unless: <<pipeline.parameters.release_kedro>>  # don't run if 'release_kedro' flag is set
    jobs:
      - sync:
          filters:
            branches:
              only: main
      - viz_build:
          filters:
            branches:
              only: main

  hourly_pr_merge:
    triggers:
      - schedule:
          cron: 0 * * * *
          filters:
            branches:
              only: main
    jobs:
      - merge_pr_to_develop

  nightly_build:
    triggers:
      - schedule:
          cron: 30 2 * * *
          filters:
            branches:
              only: main
    jobs:
      - build_docker_image
      - build_kedro:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
          requires:
            - build_docker_image

  kedro_release:
    when: <<pipeline.parameters.release_kedro>>  # only run if 'release_kedro' flag is set
    jobs:
      - build_kedro:
          matrix:
            parameters:
              python_version: ["3.6", "3.7", "3.8"]
      - publish_kedro:
          requires:
            - build_kedro
