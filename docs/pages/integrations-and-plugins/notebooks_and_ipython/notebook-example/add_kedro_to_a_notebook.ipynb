{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ff09d1",
   "metadata": {},
   "source": [
    "<!-- This is markdown extracted from the Jupyter notebook of the same name. If you want to change the content to publish as new HTML on docs.kedro.org, first `pip install jupytext`. Then open the markdown (this page) in a basic text editor (not an IDE) to make and save your changes. Next, type `jupytext --set-formats md,ipynb add_kedro_to_a_notebook.md` on the command line in the folder this file is located and regenerate the notebook. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a85cd7",
   "metadata": {},
   "source": [
    "# Add Kedro features to a notebook\n",
    "\n",
    "This page describes how to add Kedro features incrementally to a notebook.\n",
    "\n",
    "It starts with a notebook example which does NOT use Kedro. It then explains how to convert portions of the code to use Kedro features while remaining runnable within a notebook. For that part of the example, you need to have [set up Kedro](../../get_started/install.md).\n",
    "\n",
    ">**NOTE**: If you want to experiment with the code in a notebook, you can find it in the [`notebook-example` folder on GitHub](https://github.com/kedro-org/kedro/tree/main/docs/source/notebooks_and_ipython/notebook-example). Be sure to download the entire folder, or clone the entire repo, because the `add_kedro_to_spaceflights_notebook.ipynb` notebook relies upon files stored in the `notebook-example` folder.\n",
    "\n",
    "## Kedro spaceflights\n",
    "\n",
    "The [Kedro spaceflights tutorial](../../tutorial/spaceflights_tutorial.md) introduces the basics of Kedro in a tutorial that runs as a Kedro project, that is, as a set of `.py` files. The premise is as follows:\n",
    "\n",
    "_It is 2160, and the space tourism industry is booming. Globally, thousands of space shuttle companies take tourists to the Moon and back. You have been able to source data that lists the amenities offered in each space shuttle, customer reviews, and company information._\n",
    "\n",
    "_Project: You want to construct a model that predicts the price for each trip to the Moon and the corresponding return flight._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37df46",
   "metadata": {},
   "source": [
    "### The notebook example\n",
    "The full example code is given below. To run this, you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b326355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "companies = pd.read_csv(\"data/companies.csv\")\n",
    "reviews = pd.read_csv(\"data/reviews.csv\")\n",
    "shuttles = pd.read_excel(\"data/shuttles.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc836910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "companies[\"iata_approved\"] = companies[\"iata_approved\"] == \"t\"\n",
    "companies[\"company_rating\"] = (\n",
    "    companies[\"company_rating\"].str.replace(\"%\", \"\").astype(float)\n",
    ")\n",
    "shuttles[\"d_check_complete\"] = shuttles[\"d_check_complete\"] == \"t\"\n",
    "shuttles[\"moon_clearance_complete\"] = shuttles[\"moon_clearance_complete\"] == \"t\"\n",
    "shuttles[\"price\"] = (\n",
    "    shuttles[\"price\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    ")\n",
    "rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "model_input_table = rated_shuttles.merge(companies, left_on=\"company_id\", right_on=\"id\")\n",
    "model_input_table = model_input_table.dropna()\n",
    "model_input_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = model_input_table[\n",
    "    [\n",
    "        \"engines\",\n",
    "        \"passenger_capacity\",\n",
    "        \"crew\",\n",
    "        \"d_check_complete\",\n",
    "        \"moon_clearance_complete\",\n",
    "        \"iata_approved\",\n",
    "        \"company_rating\",\n",
    "        \"review_scores_rating\",\n",
    "    ]\n",
    "]\n",
    "y = model_input_table[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94df666",
   "metadata": {},
   "source": [
    "## Use Kedro for data processing\n",
    "Even if you’re not ready to work with a full Kedro project, you can still use its for data handling within an existing notebook project. This section shows you how.\n",
    "\n",
    "Kedro’s Data Catalog is a registry of all data sources available for use by the project. It offers a separate place to declare details of the datasets your projects use. Kedro provides built-in datasets for different file types and file systems so you don’t have to write any of the logic for reading or writing data.\n",
    "\n",
    "Kedro offers a range of datasets, including CSV, Excel, Parquet, Feather, HDF5, JSON, Pickle, SQL Tables, SQL Queries, Spark DataFrames, and more. They are supported with the APIs of pandas, spark, networkx, matplotlib, yaml, and beyond. It relies on [`fsspec`](https://filesystem-spec.readthedocs.io/en/latest/) to read and save data from a variety of data stores including local file systems, network file systems, cloud object stores, and Hadoop. You can pass arguments in to load and save operations, and use versioning and credentials for data access.\n",
    "\n",
    "To start using the Data Catalog, you'll need a `catalog.yml` to define datasets that can be used when writing your functions. There is one included in the same folder as your notebook:\n",
    "\n",
    "```yaml\n",
    "companies:\n",
    "  type: pandas.CSVDataset\n",
    "  filepath: data/companies.csv\n",
    "\n",
    "reviews:\n",
    "  type: pandas.CSVDataset\n",
    "  filepath: data/reviews.csv\n",
    "\n",
    "shuttles:\n",
    "  type: pandas.ExcelDataset\n",
    "  filepath: data/shuttles.xlsx\n",
    "```\n",
    "\n",
    "By using Kedro to load the `catalog.yml` file, you can reference the Data Catalog in your notebook as you load the data for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba9378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kedro's DataCatalog\n",
    "\n",
    "import yaml\n",
    "\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "# load the configuration file\n",
    "with open(\"catalog.yml\") as f:\n",
    "    conf_catalog = yaml.safe_load(f)\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bc9a0",
   "metadata": {},
   "source": [
    "The rest of the spaceflights notebook code for data processing and model evaluation from above can now run as before.\n",
    "\n",
    "## Use a YAML configuration file\n",
    "\n",
    "### Use a configuration file for \"magic numbers\"\n",
    "When writing exploratory code, it’s tempting to hard code values to save time, but it makes code harder to maintain in the longer-term. The example code for model evaluation above calls `sklearn.model_selection.train_test_split()`, passing in a model input table and outputs the test and train datasets. There are hard-code values supplied to `test_size` and `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83045559",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c67f18",
   "metadata": {},
   "source": [
    "[Good software engineering practice](https://towardsdatascience.com/five-software-engineering-principles-for-collaborative-data-science-ab26667a311) suggests that we extract *‘magic numbers’* into named constants. These could be defined at the top of a file or in a utility file, in a format such as yaml."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82828545",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# params.yml\n",
    "\n",
    "model_options:\n",
    "  test_size: 0.3\n",
    "  random_state: 3\n",
    "```\n",
    "\n",
    "The `params.yml` file is included in the example folder so you can reference the values with notebook code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4053db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"params.yml\", encoding=\"utf-8\") as yaml_file:\n",
    "    params = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = params[\"model_options\"][\"test_size\"]\n",
    "random_state = params[\"model_options\"][\"random_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8068e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"engines\",\n",
    "    \"passenger_capacity\",\n",
    "    \"crew\",\n",
    "    \"d_check_complete\",\n",
    "    \"moon_clearance_complete\",\n",
    "    \"iata_approved\",\n",
    "    \"company_rating\",\n",
    "    \"review_scores_rating\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01c9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_input_table[features]\n",
    "y = model_input_table[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc5fc4",
   "metadata": {},
   "source": [
    "The rest of the model evaluation code can now run as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a904e",
   "metadata": {},
   "source": [
    "### Use a configuration file for all \"magic values\"\n",
    "If we extend the concept of magic numbers to encompass magic values in general, it seems possible that the variable `features` might also be reusable elsewhere. Extracting it from code into the configuration file named `parameters.yml` leads to the following:\n",
    "\n",
    "```yaml\n",
    "# parameters.yml\n",
    "\n",
    "model_options:\n",
    "  test_size: 0.3\n",
    "  random_state: 3\n",
    "  features:\n",
    "    - engines\n",
    "    - passenger_capacity\n",
    "    - crew\n",
    "    - d_check_complete\n",
    "    - moon_clearance_complete\n",
    "    - iata_approved\n",
    "    - company_rating\n",
    "    - review_scores_rating\n",
    "```\n",
    "The `parameters.yml` file is included in the example folder so you can reference the values with notebook code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0459ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"parameters.yml\", encoding=\"utf-8\") as yaml_file:\n",
    "    parameters = yaml.safe_load(yaml_file)\n",
    "\n",
    "test_size = parameters[\"model_options\"][\"test_size\"]\n",
    "random_state = parameters[\"model_options\"][\"random_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_input_table[parameters[\"model_options\"][\"features\"]]\n",
    "y = model_input_table[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf4c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9178d",
   "metadata": {},
   "source": [
    "The rest of the model evaluation code can now run as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b4f61",
   "metadata": {},
   "source": [
    "## Use Kedro configuration\n",
    "Kedro offers a [configuration loader](/api/kedro.config.OmegaConfigLoader) to abstract loading values from a yaml file. You can use Kedro configuration loading without a full Kedro project and this approach replaces the need to load the configuration file with `yaml.safe_load`.\n",
    "\n",
    "### Use Kedro's configuration loader to load \"magic values\"\n",
    "To use Kedro's `OmegaConfigLoader` to load `parameters.yml` the code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e46671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedro.config import OmegaConfigLoader\n",
    "\n",
    "conf_loader = OmegaConfigLoader(conf_source=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77168832",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_params = conf_loader[\"parameters\"]\n",
    "test_size = conf_params[\"model_options\"][\"test_size\"]\n",
    "random_state = conf_params[\"model_options\"][\"random_state\"]\n",
    "X = model_input_table[conf_params[\"model_options\"][\"features\"]]\n",
    "y = model_input_table[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0993005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb70f1",
   "metadata": {},
   "source": [
    "The rest of the model evaluation code can now run as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9447c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e898a2c",
   "metadata": {},
   "source": [
    "### Use Kedro's configuration loader to load the Data Catalog\n",
    "Earlier in the example, we saw how to use Kedro's Data Catalog to load a `yaml` file, with `safe_load` and pass it to the `DataCatalog` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c26019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kedro's DataCatalog\n",
    "\n",
    "import yaml\n",
    "\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "# load the configuration file\n",
    "with open(\"catalog.yml\") as f:\n",
    "    conf_catalog = yaml.safe_load(f)\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e4e6b",
   "metadata": {},
   "source": [
    "It's also possible to use Kedro's `OmegaConfigLoader`configuration loader to initialise the Data Catalog.\n",
    "\n",
    "To load `catalog.yml` the code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34afe905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are using Kedro's ConfigLoader alongside the DataCatalog\n",
    "\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(conf_source=\".\")\n",
    "conf_catalog = conf_loader[\"catalog\"]\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26efa3d0",
   "metadata": {},
   "source": [
    "## Where next?\n",
    "At this point in the notebook, we've introduced Kedro data management (using the Data Catalog) and configuration loader. You have now \"Kedro-ised\" the notebook code to make it more reusable in future. You can go further if your ultimate goal is to migrate code out of the notebook and use it in a full-blown Kedro project.\n",
    "\n",
    "## Refactor your code into functions\n",
    "Code in a Kedro project runs in one or more pipelines, where a pipeline is a series of \"nodes\", which wrap discrete functions. One option is to put everything into a single function. Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad90a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kedro for data management and configuration\n",
    "\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(conf_source=\".\")\n",
    "conf_catalog = conf_loader[\"catalog\"]\n",
    "conf_params = conf_loader[\"parameters\"]\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")\n",
    "\n",
    "# Load the configuration data\n",
    "test_size = conf_params[\"model_options\"][\"test_size\"]\n",
    "random_state = conf_params[\"model_options\"][\"random_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09cf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_function():\n",
    "    ####################\n",
    "    # Data processing  #\n",
    "    ####################\n",
    "    companies[\"iata_approved\"] = companies[\"iata_approved\"] == \"t\"\n",
    "    companies[\"company_rating\"] = (\n",
    "        companies[\"company_rating\"].str.replace(\"%\", \"\").astype(float)\n",
    "    )\n",
    "    shuttles[\"d_check_complete\"] = shuttles[\"d_check_complete\"] == \"t\"\n",
    "    shuttles[\"moon_clearance_complete\"] = shuttles[\"moon_clearance_complete\"] == \"t\"\n",
    "    shuttles[\"price\"] = (\n",
    "        shuttles[\"price\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    )\n",
    "    rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "    model_input_table = rated_shuttles.merge(\n",
    "        companies, left_on=\"company_id\", right_on=\"id\"\n",
    "    )\n",
    "    model_input_table = model_input_table.dropna()\n",
    "    model_input_table.head()\n",
    "\n",
    "    X = model_input_table[conf_params[\"model_options\"][\"features\"]]\n",
    "    y = model_input_table[\"price\"]\n",
    "\n",
    "    ##################################\n",
    "    # Model training and evaluation  #\n",
    "    ##################################\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    model.predict(X_test)\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the one big function\n",
    "big_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf6511",
   "metadata": {},
   "source": [
    "In truth, this code is not much more maintainable than previous versions.\n",
    "\n",
    "Maybe we could do better with a series of smaller functions that map to the Kedro vision of a pipeline of nodes. A node should behave consistently, repeatably, and predictably, so that a given input  to a node always returns the same output. For those in the know, this is the definition of a pure function. Nodes/pure functions should be small single responsibility functions that perform a single specific task.\n",
    "\n",
    "Let's try this with our code. We'll split it into a set of functions to process the data, which are based on the code in `big_function` but where each function has a single responsibility. Then we'll add a set of data science functions which split the model training and evaluation code into three separate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a189f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Data processing  #\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def _is_true(x: pd.Series) -> pd.Series:\n",
    "    return x == \"t\"\n",
    "\n",
    "\n",
    "def _parse_percentage(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"%\", \"\")\n",
    "    x = x.astype(float) / 100\n",
    "    return x\n",
    "\n",
    "\n",
    "def _parse_money(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    "    x = x.astype(float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_companies(companies: pd.DataFrame) -> pd.DataFrame:\n",
    "    companies[\"iata_approved\"] = _is_true(companies[\"iata_approved\"])\n",
    "    companies[\"company_rating\"] = _parse_percentage(companies[\"company_rating\"])\n",
    "    return companies\n",
    "\n",
    "\n",
    "def preprocess_shuttles(shuttles: pd.DataFrame) -> pd.DataFrame:\n",
    "    shuttles[\"d_check_complete\"] = _is_true(shuttles[\"d_check_complete\"])\n",
    "    shuttles[\"moon_clearance_complete\"] = _is_true(shuttles[\"moon_clearance_complete\"])\n",
    "    shuttles[\"price\"] = _parse_money(shuttles[\"price\"])\n",
    "    return shuttles\n",
    "\n",
    "\n",
    "def create_model_input_table(\n",
    "    shuttles: pd.DataFrame, companies: pd.DataFrame, reviews: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "    model_input_table = rated_shuttles.merge(\n",
    "        companies, left_on=\"company_id\", right_on=\"id\"\n",
    "    )\n",
    "    model_input_table = model_input_table.dropna()\n",
    "    return model_input_table\n",
    "\n",
    "\n",
    "##################################\n",
    "# Model training and evaluation  #\n",
    "##################################\n",
    "\n",
    "\n",
    "def split_data(data: pd.DataFrame, parameters: dict) -> tuple:\n",
    "    X = data[parameters[\"features\"]]\n",
    "    y = data[\"price\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=parameters[\"test_size\"], random_state=parameters[\"random_state\"]\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> LinearRegression:\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    regressor: LinearRegression, X_test: pd.DataFrame, y_test: pd.Series\n",
    "):\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call data processing functions\n",
    "preprocessed_companies = preprocess_companies(companies)\n",
    "preprocessed_shuttles = preprocess_shuttles(shuttles)\n",
    "model_input_table = create_model_input_table(\n",
    "    preprocessed_shuttles, preprocessed_companies, reviews\n",
    ")\n",
    "\n",
    "# Call model evaluation functions\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    model_input_table, conf_params[\"model_options\"]\n",
    ")\n",
    "regressor = train_model(X_train, y_train)\n",
    "evaluate_model(regressor, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29c05f",
   "metadata": {},
   "source": [
    "And that's it. The notebook code has been refactored into a series of functions. Let's reproduce it all in one big notebook cell for reference. Compare it to the notebook code at the top of this page that began this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d071b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kedro setup for data management and configuration\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.io import DataCatalog\n",
    "\n",
    "conf_loader = OmegaConfigLoader(conf_source=\".\")\n",
    "conf_catalog = conf_loader[\"catalog\"]\n",
    "conf_params = conf_loader[\"parameters\"]\n",
    "\n",
    "# Create the DataCatalog instance from the configuration\n",
    "catalog = DataCatalog.from_config(conf_catalog)\n",
    "\n",
    "# Load the datasets\n",
    "companies = catalog.load(\"companies\")\n",
    "reviews = catalog.load(\"reviews\")\n",
    "shuttles = catalog.load(\"shuttles\")\n",
    "\n",
    "# Load the configuration data\n",
    "test_size = conf_params[\"model_options\"][\"test_size\"]\n",
    "random_state = conf_params[\"model_options\"][\"random_state\"]\n",
    "\n",
    "\n",
    "####################\n",
    "# Data processing  #\n",
    "####################\n",
    "\n",
    "\n",
    "def _is_true(x: pd.Series) -> pd.Series:\n",
    "    return x == \"t\"\n",
    "\n",
    "\n",
    "def _parse_percentage(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"%\", \"\")\n",
    "    x = x.astype(float) / 100\n",
    "    return x\n",
    "\n",
    "\n",
    "def _parse_money(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    "    x = x.astype(float)\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_companies(companies: pd.DataFrame) -> pd.DataFrame:\n",
    "    companies[\"iata_approved\"] = _is_true(companies[\"iata_approved\"])\n",
    "    companies[\"company_rating\"] = _parse_percentage(companies[\"company_rating\"])\n",
    "    return companies\n",
    "\n",
    "\n",
    "def preprocess_shuttles(shuttles: pd.DataFrame) -> pd.DataFrame:\n",
    "    shuttles[\"d_check_complete\"] = _is_true(shuttles[\"d_check_complete\"])\n",
    "    shuttles[\"moon_clearance_complete\"] = _is_true(shuttles[\"moon_clearance_complete\"])\n",
    "    shuttles[\"price\"] = _parse_money(shuttles[\"price\"])\n",
    "    return shuttles\n",
    "\n",
    "\n",
    "def create_model_input_table(\n",
    "    shuttles: pd.DataFrame, companies: pd.DataFrame, reviews: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    rated_shuttles = shuttles.merge(reviews, left_on=\"id\", right_on=\"shuttle_id\")\n",
    "    model_input_table = rated_shuttles.merge(\n",
    "        companies, left_on=\"company_id\", right_on=\"id\"\n",
    "    )\n",
    "    model_input_table = model_input_table.dropna()\n",
    "    return model_input_table\n",
    "\n",
    "\n",
    "##################################\n",
    "# Model training and evaluation  #\n",
    "##################################\n",
    "\n",
    "\n",
    "def split_data(data: pd.DataFrame, parameters: dict) -> tuple:\n",
    "    X = data[parameters[\"features\"]]\n",
    "    y = data[\"price\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=parameters[\"test_size\"], random_state=parameters[\"random_state\"]\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> LinearRegression:\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    regressor: LinearRegression, X_test: pd.DataFrame, y_test: pd.Series\n",
    "):\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    print(r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Call data processing functions\n",
    "preprocessed_companies = preprocess_companies(companies)\n",
    "preprocessed_shuttles = preprocess_shuttles(shuttles)\n",
    "model_input_table = create_model_input_table(\n",
    "    preprocessed_shuttles, preprocessed_companies, reviews\n",
    ")\n",
    "\n",
    "# Call model evaluation functions\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    model_input_table, conf_params[\"model_options\"]\n",
    ")\n",
    "regressor = train_model(X_train, y_train)\n",
    "evaluate_model(regressor, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
